タイトルの通りAWS Summit Tokyo 2017のDay2とDay3に参加してきたのでその参加レポ。この記事はDay2について記載。そもそも私はAWS Summitにこれまで参加したことがなく、AWSについても十分に使えてたわけではなくこれから本格的に使っていこうとしている時だったので自分にとっては大変為になった2日間だった。

# 基調講演

まず基調講演会場に入って真っ先に思ったのはめっちゃ広い!!ってこととめっちゃ豪華!!ってこと。この先もそうだけどこれが無料で参加できるなんてさすがAmazon様。

https://twitter.com/taisa831/status/869717523909853184

## オープニング

三味線・バイオリン・ギターのスペシャルライブから始まった。これはめちゃくちゃよくてもっと聞いていたい感じだった。

https://twitter.com/awscloud_jp/status/869723273965182976

## アマゾン ウェブ サービス ジャパン 長崎忠雄

オープニングのスペジャルライブが終わりホストスピーカーとしてAWS Japan代表取締役社長が出てきた。スピーチは社長らしく今回は去年と違って規模が約2倍であることやAWSのこれまでの成長具合と現状とこれからの未来について話された。あとサービスコンソールが6月末まえに100%日本語化すると明言していた。厳密には以降ホストとゲストが入れ替わってスピーチしていたがスピーチメモは以下まとめて記載する

### メモ
- Registration 20,000人以上
- 世界で一番多い
- 去年の2倍の規模
- スタートアップ企業の支援を強化
- 16分野のコンピテンシーがある
- 事例大全集ダウンロードできる
- ユーザコミュニティがある
- エンタープライズ版もある
- サービスコンソールを6月末までに100%日本語化予定
- 現在90以上のサービスがある
- 2016年には1017の新サービスおよび機能改善数
    - 数年前は100程度だった
- Amazon AIすごいよってことでルービックキューブ動画を再生
    - パターンが多いので普通なら35年ほどかかるのが0.9秒になる
- 他にもマシンラーニングを導入した企業のコスト削減の紹介
    - コスト1億円削減
    - 10日かかってたのが10分に削減など
- 5/31からAmazon LightsailがTokyoリージョンで使えるように
    - データ転送量込みで月額5ドルから
- いろんな企業にとってデータの移行の課題が大きい
    - AWS Database Migration ServiceでDBを簡単に移行ができるので現在25,000以上が移行済みである
- ペタバイト急のデータ移行もある
    - そんな場合はAWS Snowballが利用できる
    - 東京リージョンはプライベートプレビュー
- AWSサポートの充実
    - ベーシック
    - 開発者向け
    - エンタープライズ向けなど
- コストダウンについて
    - これまで2006年のサービスインから明確な競合がいないにもかかわらず61回の値下げをしてる
    - これはユーザファーストであることの表れ
- オンプレからAWSとのハイブリットのつなぎを重要視
- フルマネージドサービスで運用負荷軽減
- 災害に対するリスクは高い
    - 2018にOsaka Regionが利用可能になる予定
- セキュリティとコンプライアンスをファーストプライオリティとしている

## ゲストスピーカー/三菱UFJファイナンシャルグループ 村林 聡

まず初めのゲストスピーカーは三菱UFJファイナンシャルグループ執行役専務グループCIO。まず最初に自分たちはレガシーな企業だと2回程念を押すように言ったのち、これからはデジタルトランスフォーメーション、オープンイノベーションへ向かっていくという話をされた。具体的にはAPI、BlockChain、AIなどを駆使し7年後には銀行のコアの業務を4割ほどをAIに置き換えられるのではないかと。また、現在はオンプレから順次AWSへサーバ移行中で、現在は5つ程稼働しているが、100程が移行検討中である。ただ最後に今期で退任して次のところへ行きますといって締めていったのでなんとも言えない空気になった。

### メモ
- デジタルトランスフォーメーション、オープンイノベーションへ
- オンプレから移行予定
- AWSでは現在稼働中5つ
    - 100くらい検討中
- 今期で退任する

## ゲストスピーカー/セイコーエプソン 熊倉一徳

続いてのゲストスピーカーはセイコーエプソン株式会社のIT推進本部 本部長が登壇。セイコーエプソンは創業当時からものづくりの企業でありリアルな世界にこれからも提供していくのは変わらないといった一方で現在はサイバー空間も重要視し力を入れている。

### メモ

- ものづくりの企業
- リアルな世界に提供するのは変わらない
- サイバー空間も重要視
- クラウドへの移行はかなり困難だった
- サーバレスアーキテクチャを採用

## ゲストスピーカー/レコチョク 稲荷 幹夫

続いてのゲストスピーカーはレコチョク執行役員CTOが登壇。レコチョクも最初はガラケーからの発信だったので大変だったが、現在はAWSへ全面移行することができた。当時の一番懸念点はやはりDBだったが、移行後は運用工数0、ライセンス費用0（オラクルだった）、パフォーマンス障害0になりかなり健康な状態が保てている。

### メモ

- 現在はVRの取り組みに力を入れている

## ゲストスピーカー/Sansan 塩見 賢治

最後のゲストスピーカーはSansan株式会社Co-founder Eight事業部 事業部長が登壇。AWSサービスは30以上使っていてそのメリットはセキュリティ、止まらない、拡張性高いと言及した

# セッション

## IoT/Bigdata/AI時代におけるスケーラブルなDeepLearning実行基盤と応用

### ABEJA スピーカー
- カズンズ・ジェーン

前半は、Pythonistaの海外出身のエンジニアの方が話、後半は日本人のAWSに精通しているインフラエンジニアが登壇した。前半では簡単に言うとPythonずっと使ってるけどいいよっていう話がされてたと思う。後半ではアーキテクチャについて割と細かく説明されていた。詳しくは以下のメモとして記載。

### Pythonistaのエンジニア

- AIを投入する
- LocalでAIを導入
- Lambda利用でchaliceやzappaあるよ
- Falcon APIに特化して使うのいいよ
- Python Fireいいよ (Google製)

### DeepLearningのスケール

Deep Learningの開発プロセス

- データを集める
    - Collection
    - Annotation(pandas、numpy）
- Model Depelopment
    - Exploration
    - Training（jupyterなど）
- Model Management
    - Inferring
- Monitoring
    - Falcon、Requests

### AWSアーキテクチャについて

#### データ収集

- Kinesis Streams
    - スケーラブルなQueueサービス
    - 1000req/sec/shard

#### データの保管

- 言わずもがなS3
- データレイク

#### 学習環境で意識していること

- 並列実行やGPU環境
- スケーラビリティの高い環境
- 安価に必要な時に必要な分だけ
- 開発スピードを落とさないように
- ECS
  - マネージドなDocker管理サービス
  - EC2の上に薄く載る感じ
  - ローカルで開発可能
  - 少しパラメータを変えて数十台分同時実行することも可能
  - GPUも利用可能

#### なぜGPU？

- Core数が多くて並列計算が得意
- 行列計算が得意

#### アーキテクチャ

- API Gateway → Kinesis → Lambda → S3
- ECS → LB → Annotation → S3

※ Kinesisに依存しないためにAPI Gatewayを利用してる
※ kinesis firehose使ってみたい
※ API Gatewayはできればやめたい
※ データにAWS Glueも興味ある

#### モデル作成

- S3からトレーニングデータを取得してECSでJupiterなどを使ってS3に返す
    - Scalable
    - AWS Batch
    - Spot Fleet

#### Model Management

- CodeBuild

#### アーキテクチャ

- S3を間に置いて疎結合にしてる

#### まとめ

- 疎結合を意識してる
- AIの過渡期だから小さく開発を意識している

## ChatWorkの新メッセージングシステムを支える技術

### ChatWorkスピーカー
- かとじゅんさん
- 大村 伸吾

こちらも前半はプログラムサイドの話がメインで後半にインフラサイドの話という構成だった。ただ前半のプログラムサイドの話については最初以外は話が難しくてほぼ分からなかった。あとあえて言うとおそらくだけど発表者ノートをひたすら読み上げる形の発表だったので聞いているのが若干辛かった。これは自分が発表する際には気をつけないとなと思うポイントだった。

### アーキテクチャ詳解

- CharWorkは当初社内FW+既存システムの相乗りでサービス公開した
- なんとか改善しながらやってきたが限界がきてシステム刷新を決断
- 最初はライブマイグレーションプランで移行を実行したがいろんな問題が起きてプロジェクトを再起動することになった
- 新しいアーキテクチャに移行することにして2016年に大規模なデータ移行を完了した

### 新しいアーキテクチャの方針

- メッセージ数の遷移が毎年増大している背景がある
- 保守性を維持するためにDDDは継続
- リアクティブシステム(Akka)をベースにしたCQRS+ESを採用
- cassandra + aurora

### モチベーション

- 当初はEC2、Jenkins、Capipstrano、Fabricだった
- 困ってたこと
  - デプロイフローの改修が大変
  - 負荷試験をカジュアルにやりたい
- 新しいアーキテクチャで達成できたこと
  - 負荷試験が通ったアプリコードを開発チームだけで維持できた

### どうやった？

- 実行環境をKubernetesにCIをConcourse CIに
- 負荷テストツールの自動化(ECS等)

### それぞれ

- Kubernetesにした理由
  - デファクト
  - 開発が活発
  - kube-awsのメンテナの@mumoshuさんが社内にいる
  - ローカル開発環境minicubeがある
  - インフラチームと開発チームの責務が分離できる
- 責務の分離
  - 必要なAWSリソースはteraformを利用

### concourse CI
- 特徴
  - パイプライン
  - YAML
  - Dependable Results
  - プラグインが不要
- CIサーバの運用が楽になった
- ローカルで開発したパイプラインがそのまま本番にデプロイできる
- vagrant upで簡単にローカル起動可能
- Gitlab flow with Environment Branchesを採用

### 負荷テストの自動化
- これまではFullBokを利用していた
- Amazon ECS + Gatlingを使った負荷テスト自動化ツールの導入
- DSLでシナリオがコードで作れる
- Gatlingの苦手
  - クラスタ実行
  - 複数レポートのaggregation

## 【ライブコーディングも実施】Amazon Payの仕組みと実装方法

### アマゾンジャパン スピーカー
- Johnathan David Froeming
- 吉村周造

このセッションは二人とも熱のあるスピーチでとてもよかった。Amazonがいかにユーザのことを突き詰めて考えているかというのがとても伝わってきた。ECの最大の目的は商品の購入であることやユーザにとって一番よいESサイトは画面遷移と入力が最小限であることだということをひたすら伝えていた。Amazon Payの存在をすっかり忘れていたけど使いたくなった。

## Amazon Pay特徴
- 利便性
- スピード（2クリック）
- 安心感（マケプレ保証）
- 実績1000社オーバー

## 日本赤十字社の例
- 熊本地震がきっかけ
    - 寄付はしてみたいけど・・・
    - より多くの人にネット経由で寄付をしてもらいたい
- 課題
    - 信頼できるページが必要（amazon.co.jp）
    - 管理を楽にしたい（aws)    
- すぐに開始したい
  - JSとSDK開発のみですぐに開始できる
- Amazon Payの仕組み
  - フロント：Javascriptだけで可能
  - バックエンド：SDKで実装
- LB+EC2?もしくはAPI Gateway+Lambda?
  - Lambdaを選択した
  - 困ってる人を早く助けたい（AWSならそれができる）
  - グローバルでも利用が可能
- 購入画面のBest Practice（ECサイトのゴールは何？）
    - 商品購入（たくさん商品を購入してほしい）
- 代表的な課題にカゴ落ちがある
    - カゴ落ちの一番の理由は？それは面倒だから（入力が多すぎる）
- amazon payは商品購入の機会を最大化できる
- AmazonのGolden Rule14項目を日本初公開した
  - 1ページで購入
  - 項目は最小限
  - ゲスト購入OK
- ライブコーディング実施（ウィジェットを読み込むコーディング）

## GunosyにおけるAWS上での自然言語処理・機会学習の活用事例

### Gunosyスピーカー
- 大曽根 圭輔

### 所感

### サマリ

- ニュースパスアプリ
- ユーザの行動分析を担当
- ブログ開設してる
  - http://data.gunosy.io/
- JSAI 2017, COLING 2016に参加
- 8割当たる予測機をつくるのは難しくない時代だがユーザ満足につなげるのはまだ壁がある
- Gunosyと機会学習
  - 600超の媒体と契約し記事を収集して分類してリスト作成してユーザに届ける
  - 記事分類
    - 文言からカテゴリ分類
  - 同一イベント判定
    - 内容が似ている記事をまとめる
  - 代表記事選択
  - ユーザの行動ログをリアルタイムで収集
  - ユーザの属性推定
    - スコアリング（ユーザ属性ごとのCTR予測しリストを並べ替え）
      - 評価（配信アルゴリズムの効果を測定）
- 記事分類
  - 大中小でカテゴライズしている
  - 形態素解析
  - カテゴリ分類器
  - カテゴリ分類APIにエンキューして分類してRDBに格納
  - Ops
  - モデルはS3に保存してdeploy時に
- 属性推定+スコアリング
  - ユーザ行動ログ→ユーザ属性推定→スコアリング
  - 属性毎に性別、年齢、地域でクリックの傾向がかなり別れる
  - どうやって属性を知るか
    - ユーザが読んだ記事情報をもとに属性を推定している
  - 年齢推定にはCNN for NLPを応用
    - 畳み込みニューラルネットワークを使ってる
  - AWSでは？
    - ユーザのログをS3に格納
    - GPUインスタンスを使って学習させてる
    - 集計後データをRDBに入れる
    - prestoを使ってslackやredashなどで可視化して随時通知したり表示
    - logはkinesis streamを利用、kinesis analyticsで集計してkinesis firehorseを使ってelasticsearch serviceから検索（リアルタイム通知）
  - 評価（ABテスト）
    - よくない例は機能リリース後に大きなイベントが発生してやまが大きくなると計測不能
    - イベントに左右されにくい
    - ABテスト対象の選定
      - ハッシュ関数を利用した割り当てをしてる
  - スコアリング(Python)→Dynamo DB→ 記事リストAPI（Go)→ユーザ
    - どのABにあたってるかをs3にいれる。
    - 細かいことを確認するにはjupiter notebookを使ったりしてる
    - Github上で集計コードを共通化
- 自動集計
  - Group Validation
  - ABテストが適切に割り当てられてるか
  - 自動化進行中
- 伝えたかったこと
  - 実際のサービスで動かすことが重要
  - gunosy-dm.connpass.com
    - 勉強会もやってる
